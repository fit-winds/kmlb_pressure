{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_kmlb_data.py\n",
    "# bryan holman // v0.2 // 20171005\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import shutil\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input integers of current year and month, return strings of next month to grab data\n",
    "def get_next_month(yr, mo):\n",
    "    mo_next = dt.datetime(yr, mo, 1, 0, 0, 0) + dt.timedelta(weeks = 5)\n",
    "    year = str(mo_next.year)\n",
    "    if mo_next.month < 10:\n",
    "        month = '0' + str(mo_next.month)\n",
    "    else:\n",
    "        month = str(mo_next.month)\n",
    "    return [year, month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing data for 09/2017 ...\n"
     ]
    }
   ],
   "source": [
    "month_data = pd.read_csv('../data/processed_months.csv')\n",
    "mo = month_data['month'][-1:].values[0]\n",
    "yr = month_data['year'][-1:].values[0]\n",
    "year, month = get_next_month(yr, mo)\n",
    "print('Grabbing data for ' + month + '/' + year + ' ...')\n",
    "data_url = ('ftp://ftp.ncdc.noaa.gov/pub/data/asos-onemin/6406-' + year + \n",
    "    '/64060KMLB' + year + month + '.dat')\n",
    "column_names = ['Station', 'DateTime', 'Note1', 'Note2', 'Note3', 'Pres1', \n",
    "                'Pres2', 'Pres3', 'Tmp', 'Dwpt']\n",
    "                \n",
    "# only continue if the data for this month are available\n",
    "try:\n",
    "    kmlb_data = pd.read_fwf(data_url, header=None, names=column_names)\n",
    "except:\n",
    "    error_msg = ('KMLB data for ' + month + '/' + year + \n",
    "                 ' are not available yet. Please try again later.')\n",
    "    print(error_msg)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data ...\n",
      "Writing to disk ...\n",
      "Write successful. Appending to data all data ...\n",
      "Backing up KMLB_all.csv ...\n"
     ]
    }
   ],
   "source": [
    "print('Processing data ...')\n",
    "# drop columns we don't need\n",
    "kmlb_data = kmlb_data.drop(['Station', 'Note1', 'Note2', 'Note3', 'Tmp', 'Dwpt'], axis=1)\n",
    "\n",
    "# convert to time series in UTC\n",
    "try:\n",
    "    kmlb_data['DateTime'] = pd.to_datetime(kmlb_data['DateTime'].str[3:15])\n",
    "# some of the files' fixed width nature isn't quite right ... this fixes that\n",
    "except ValueError:\n",
    "    print('Inferring columns failed. Attempting to do so manually ...')\n",
    "    kmlb_data = pd.read_fwf(data_url, header=None, dtype=object,\n",
    "                            colspecs=[[13, 25], [70, 76], [78, 84], [86, 92]], \n",
    "                            names=['DateTime', 'Pres1', 'Pres2', 'Pres3'])\n",
    "    kmlb_data['DateTime'] = pd.to_datetime(kmlb_data['DateTime'])\n",
    "kmlb_data = kmlb_data.set_index('DateTime')\n",
    "kmlb_data = kmlb_data.tz_localize('EST').tz_convert('UTC')\n",
    "\n",
    "# make sure each column is a float\n",
    "for col in ['Pres1', 'Pres2', 'Pres3']:\n",
    "    if not kmlb_data[col].dtype == np.float64:\n",
    "        kmlb_data[col] = pd.to_numeric(kmlb_data[col], errors='coerce')\n",
    "\n",
    "# remove duplicate values and sample every five minutes\n",
    "kmlb_data5 = kmlb_data[~kmlb_data.index.duplicated(keep='first')].asfreq('5Min')\n",
    "del(kmlb_data, data_url, column_names, col)\n",
    "\n",
    "# convert from inHg to Pa and add 200 Pa to get to sea level\n",
    "kmlb_data5['Pressure (Pa)'] = kmlb_data5.mean(axis=1, skipna=False) * 3386.38816\n",
    "kmlb_data5['MSLP (Pa)'] = kmlb_data5['Pressure (Pa)'] + 200\n",
    "\n",
    "# drop original pressure column_names\n",
    "kmlb_data5 = kmlb_data5.drop(['Pres1', 'Pres2', 'Pres3'], axis=1)\n",
    "\n",
    "# write csv file to disk with proper date format (per Peyman's liking) and\n",
    "# fill missing values with 999999\n",
    "print('Writing to disk ...')\n",
    "filename = '../data/KMLB' + year + month + '.csv'\n",
    "kmlb_data5.to_csv(filename, date_format='%d-%b-%Y %H:%M:%S', \n",
    "                  float_format='%.6f', na_rep='999999')\n",
    "\n",
    "# now let's append this new data to all KMLB data\n",
    "print('Write successful. Appending to data all data ...')\n",
    "print('Backing up KMLB_all.csv ...')\n",
    "shutil.copy('../data/KMLB_all.csv', '../data/KMLB_all_old.csv')\n",
    "\n",
    "# load and preprocess all KMLB data\n",
    "all_data = pd.read_csv('../data/KMLB_all.csv', na_values='999999')\n",
    "all_data['DateTime'] = pd.to_datetime(all_data['DateTime'], format='%d-%b-%Y %H:%M:%S')\n",
    "all_data = all_data.set_index('DateTime')\n",
    "all_data = all_data.tz_localize('UTC')\n",
    "\n",
    "# append new data to all data and remove duplicates. This is important in case\n",
    "# we accidentally just processed a month that is already contained in the data\n",
    "concat_data = pd.concat([all_data, kmlb_data5])\n",
    "concat_data = concat_data[~concat_data.index.duplicated(keep='first')]\n",
    "\n",
    "# now write this to disk\n",
    "concat_data.to_csv('../data/KMLB_all.csv', date_format='%d-%b-%Y %H:%M:%S', \n",
    "                   float_format='%.6f', na_rep='999999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month\n",
       "31  2017      5\n",
       "32  2017      6\n",
       "33  2017      7\n",
       "34  2017      8\n",
       "35  2017      9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update processed_data.csv\n",
    "month_data.loc[len(month_data)] = [int(year), int(month)]\n",
    "month_data.to_csv('../data/processed_months.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# commit to github if applicable\n",
    "from git import Repo\n",
    "import os\n",
    "repo = Repo(os.getcwd())\n",
    "file_list = [filename, 'data/KMLB_all_old.csv', 'data/KMLB_all_old.csv']\n",
    "commit_message = 'Add data for ' + month + '/' + year\n",
    "repo.index.add(file_list)\n",
    "repo.index.commit(commit_message)\n",
    "origin = repo.remote('origin')\n",
    "origin.push()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
